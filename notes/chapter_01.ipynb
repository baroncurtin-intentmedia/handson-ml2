{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Chapter 1 - The Machine Learning Landscape\n",
    "This chapter primarily introduces a lot of the fundamental concepts and jargon that everyone practicing ML should know."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 What is Machine Learning\n",
    "\n",
    "- Machine Learning is the science (and art) of programming computers so they can *learn from data*\n",
    "- The set of data that a machine learning system uses to learn from is called the *training set*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Why Use Machine Learning\n",
    "\n",
    "- It is great for problems for which existing solutions require a lot of fine-tuning or long lists of rules\n",
    "    - Often, a ML algorithm can simplify code and perform better than the traditional approach\n",
    "- ML techniques can possibly find a solution for complex problems for which using a traditional approach doesn't yield\n",
    "a good solution\n",
    "- ML systems can easily adapt to new data from fluctuating environments\n",
    "- Getting insights about complex problems and large amounts of data\n",
    "    - Applying ML techniques to dig into large amounts of data can help discover patterns that were not immediately apparent\n",
    "    is called *data mining*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Examples of Applications\n",
    "- *Image Classification* is the analysis of images in an attempt to automatically identify them as particular objects/shapes/etc.\n",
    "    - Typically performed using convolutional neural networks (CNN)\n",
    "- *Semantic Segmentation* is the analysis of an image where each pixel is classified\n",
    "    - Typically performed using convolutional neural networks\n",
    "    - Used to determine the exact location and shape of tumors\n",
    "- *Text Classification*\n",
    "    - Automatically flagging offensive comments on discussion forums\n",
    "    - Is a part of Natural Language Processing (NLP)\n",
    "- *Text Summarization*\n",
    "    - Automatically summarizing long documents\n",
    "    - Also NLP\n",
    "- *Chatbot*\n",
    "    - Involves NLP components including understanding and question-answering modules\n",
    "- *Regression*\n",
    "    - Forecasting company revenue next year based on performance metrics\n",
    "    - Can be performed using Linear Regression, Polynomial Regression, Support Vector Machine (SVM), Random Forest,\n",
    "    Neural Network\n",
    "- *Speech Recognition*\n",
    "    - Audio samples are processed for speech recognition\n",
    "    - Typically uses Recurrent Neural Networks (RNNs), CNN, or transformers\n",
    "- *Anomaly Detection*\n",
    "    - Detecting fraud\n",
    "- *Clustering*\n",
    "    - Segmenting clients based on their purchases so that you can design a different marketing strategy for each segment\n",
    "- *Dimensionality Reduction*\n",
    "- *Recommender Systems*\n",
    "    - Usually done with the use of Neural Networks\n",
    "- *AI Bots for Games*\n",
    "    - Usually done through reinforcement learning (RL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 Types of Machine Learning Systems\n",
    "\n",
    "- Machine Learning systems can be broadly classified into these broad categories:\n",
    "    - Whether or not they are training with human supervision (supervised, unsupervised, semisupervised, and reinforcement learning)\n",
    "    - Whether or not they can learn incrementally on the fly\n",
    "    - Whether they work by simply comparing new data points to known data points or instead by detecting patterns in the training data\n",
    "    and building a predictive models (instance-based versus model-based learning)\n",
    "    \n",
    "### 1.4.1 Supervised/Unsupervised Learning\n",
    "\n",
    "- There are 4 major categories (how they learn):\n",
    "    - Supervised learning\n",
    "    - Unsupervised learning\n",
    "    - Semisupervised learning\n",
    "    - Reinforcement learning\n",
    "    \n",
    "#### 1.4.1.1 Supervised Learning\n",
    "\n",
    "- In *supervised learning*, the training set you feed to the algorithm includes the desired solutions called *labels*\n",
    "- A typical supervised learning task is *classification*\n",
    "- Another typical task is to predict *target* numeric values given a set of *features* called *predictors* called *regression*\n",
    "- An *attribute* is a data type\n",
    "- A *feature* generally means an attribute with its value\n",
    "\n",
    "#### 1.4.1.2 Unsupervised Learning\n",
    "\n",
    "- In *unsupervised learning* the training data in unlabeled\n",
    "- The system will try to learn without any intervention\n",
    "- Some important unsupervised learning tasks include:\n",
    "    - Dimensionality reduction\n",
    "    - Anomaly detection\n",
    "    - Novelty detection\n",
    "    - Association rule learning\n",
    "    \n",
    "#### 1.4.1.3 Semisupervised Learning\n",
    "\n",
    "- This type of learning system deals with data where the data is only partially labelled\n",
    "- Most semisupervised learning algorithms are combinations of unsupervised and supervised algorithms\n",
    "\n",
    "#### 1.4.1.4 Reinforcement Learning\n",
    "\n",
    "- This system involves an *agent* that can observe the \"environment\", select and perform actions, and get *rewards* in return\n",
    "    - These rewards can be positive or negative (penalties)\n",
    "- The system then learns by itself what the best strategy is, called a *policy*, where it maximizes the reward over time\n",
    "\n",
    "### 1.4.2 Batch and Online Learning\n",
    "\n",
    "#### 1.4.2.1 Batch Learning\n",
    "\n",
    "- In *batch learning*, the system is incapable of learning incrementally meaning it must be trained using all the available data\n",
    "- The system is training, and then it is launched into production and runs without learning anymore; it just applies what\n",
    "it has learned called *offline learning*\n",
    "    - If you want a batch learning system to know about new data, yuo need to train a new version of the system from scratch\n",
    "    on the full dataset and replace the old one with the new one\n",
    "    \n",
    "#### 1.4.2.2 Online Learning\n",
    "\n",
    "- In *online learning*, you train the system incrementally by feeding it data instances sequentially, either individually \n",
    "or in small groups called *mini-batches*\n",
    "- *Online learning* is great for system that need to adapt to change rapidly\n",
    "- *Online learning* can also be used to training systems on huge datasets that cannot fit in one machine's main memory \n",
    "(called *out-of-core* learning)\n",
    "- An important parameter of online learning systems is how fast they should adapt to changing data: this is called the \n",
    "*learning rate*\n",
    "    - High learning rates mean the system will rapidly adapt to new data but will also quickly forget what it has learned\n",
    "    - Low learning rates mean the system will remember longer but also adapt to new data more slowly\n",
    "\n",
    "### 1.4.3 Instance-Based Versus Model-Based Learning\n",
    "\n",
    "- One more way to categorize ML systems is by how they *generalize*\n",
    "    - How well does the system adapt to new (unseen) data?\n",
    "- Two main approaches to generalization:\n",
    "    - Instance-based learning\n",
    "    - Model-based learning\n",
    "    \n",
    "#### 1.4.3.1 Instance-Based Learning\n",
    "\n",
    "- Instance-based learning is basically \"learning by heart\" or using existing examples, and flagging new examples when they\n",
    "are identical to previous examples\n",
    "- The other method to instance-based learning is using a *measure of similarity* where new examples are compared to previous\n",
    "examples, and if they meet some threshold, are identified as such\n",
    "\n",
    "#### 1.4.3.2 Model-Based Learning\n",
    "\n",
    "- Model-based learning is the method of generalizing from a set of examples by building a model from those examples, and then\n",
    "using the model to make *predictions*\n",
    "- In order to do model-based learning, you need to specify a performance measure\n",
    "    - This is often done through defining a *utility function* (or *fitness function*) that measures how good the model is\n",
    "    - This can also be defined as a *cost function* (or how bad a model is)\n",
    "    - For Linear Regression, the cost function typically revolves around a measure of distance between the predictions and\n",
    "    the actual values, and the model works to minimize this distance\n",
    " \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.5 Main Challenges of Machine Learning\n",
    "\n",
    "- The two things that can go wrong are \"bad algorithm\" and \"bad data\"\n",
    "\n",
    "### 1.5.1 Insufficient Quantity of Training Data\n",
    "\n",
    "- In general, given enough data, simple ML models can perform just as well (or better) as more complex models\n",
    "- There is an inherent trade-off that must be considered when thinking about spending time and money on algorithm development\n",
    "and corpus development (training data)\n",
    "\n",
    "### 1.5.2 Nonrepresentative Training Data\n",
    "\n",
    "- In order to generalize well, it is crucial that your training data be representative of the new cases you want to generalize to\n",
    "    - It is crucial to use a training set that is representative of the cases you want to generalize to\n",
    "    - If the sample is too small, you will have *sampling noise* (nonrepresentative data as a result of chance)\n",
    "    - Another source of error is from *sampling bias*, when the sampling method is flawed\n",
    "    \n",
    "### 1.5.3 Poor-Quality Data\n",
    "\n",
    "- If the training data is full of errors, outliers, and noise, it will be harder for the algorithm to detect patterns, and thus\n",
    "your system is highly likely to perform poorly\n",
    "    - Severe outliers can be be discarded or dealt with manually\n",
    "    - Whenever a feature is missing a lot of information, action must be taken whether it is to:\n",
    "        - Ignore the feature\n",
    "        - Fill in the missing values\n",
    "        - Ignore the instances of missing values\n",
    "        - Train two models with and without the feature\n",
    "        \n",
    "### 1.5.4 Irrelevant Features \n",
    "\n",
    "- One of the most important parts of a successful ML project is *feature engineering*, or coming up with a good set of features\n",
    "to train on. This process involves the following steps:\n",
    "    - *Feature selection*: selecting the most useful features to train on among existing features\n",
    "    - *Feature extraction*: combining existing features to produce a more useful one\n",
    "    - Creating new features by gathering new data\n",
    "    \n",
    "### 1.5.5 Overfitting the Training Data\n",
    "\n",
    "- Overfitting is when the model performs well on the training data, but does not generalize well to new data\n",
    "    - Complex models such as deep neural networks are able to detect subtle patterns in data and because of this, if a dataset\n",
    "    is noisy or too small, the model will likely feel like the noise is useful information\n",
    "- Overfitting can be solved by:\n",
    "    - Simplifying the model\n",
    "        - Selecting a model with fewer parameters\n",
    "        - Reducing the number of attributes in the training data\n",
    "        - Constraining the model\n",
    "    - Gathering more training data\n",
    "    - Reduce the noise in the training data\n",
    "        - Fix errors\n",
    "        - Remove outliers\n",
    "- Constraining a model to make it simpler and reduce the risk of overfitting is called *regularization*\n",
    "- The ultimate objective is to find the right balance between fitting the training data and keeping the model simple so that \n",
    "it can generalize well\n",
    "- Regularization is typically controlled through *hyperparameters*\n",
    "    - *Hyperparameters* are parameters of a learning algorithm and not the model itself\n",
    "    \n",
    "### 1.5.6 Underfitting the Training Data\n",
    "\n",
    "- This occurs when the model is too simple to learn the underlying structure of the data\n",
    "- The main options for solving this problem are:\n",
    "    - Selecting a more powerful model, with more parameters\n",
    "    - Feed better features to the learning algorithm (feature engineering)\n",
    "    - Reduce the constraints on the model (reduce the regularization parameters)\n",
    "    \n",
    "### 1.5.7 Stepping Back\n",
    "\n",
    "- ML is about making machines get better at some task by learning from data instead of having to explicitly code rules\n",
    "- There are many different types of ML systems: supervised or not, batch or online, instance-based or model-based\n",
    "- In an ML project, you gather data in a training set, feed the training set to a learning algorithm:\n",
    "    - If the algorithm is model-based, it tunes some parameters to fit the model to the training data\n",
    "    - If the algorithm is instance-based, it just learns the examples by heart and generalizes to new instances by using\n",
    "     a similarity metric\n",
    " - The system will not perform well if your training set:\n",
    "    - Is too small\n",
    "    - Not representative\n",
    "    - Is noisy\n",
    "    - Is polluted with irrelevant features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.6 Testing and Validating\n",
    "\n",
    "- The only way to know how well a model will generalize to new cases is to actually try it out on new cases\n",
    "- This is accomplished by splitting your data into two sets:\n",
    "    - The *training set*\n",
    "    - The *test set*\n",
    "    - It is very common to use 80% of the data for training and 20% on testing\n",
    "- The error rate on new cases is called the *generalization error* and this estimate can be determined by the performance \n",
    "of the model on the *test set*\n",
    "- If the training error is low, but the generalization error is high, it means that your model is overfitting the training\n",
    "data\n",
    "\n",
    "### 1.6.1 Hyperparameter Tuning and Model Selection\n",
    "\n",
    "- Evaluating a model is done on the *test set*\n",
    "- A common solution to solving generalization error on a *test set* is to use a *holdout validation* set or *validation set*\n",
    "    - You can use this set to evaluate several models and select the best one\n",
    "    - This is also the time to experiment with different hyperparameters\n",
    "- The pitfalls of using a single validation set are solved through repeated *cross-validation*\n",
    "    - This uses many small *validation sets*\n",
    "    - Each model is evaluated once per validation set after it is training on the rest of the data\n",
    "    - The error measure on all those models will give a better measure of the performance\n",
    "\n",
    "### 1.6.2 Data Mismatch\n",
    "\n",
    "- This is when the data is not perfectly representative of the data that will be used in production"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}